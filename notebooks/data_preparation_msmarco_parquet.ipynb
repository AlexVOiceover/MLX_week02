{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS MARCO Data Preparation from Parquet Files\n",
    "\n",
    "This notebook processes the MS MARCO Passage Ranking dataset from local parquet files for our Learn to Rank project. We'll create a structured JSON format to use in our learning to rank model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset size controls - useful for development\n",
    "MAX_SAMPLES = None  # Set to a number for development, None for full dataset\n",
    "USE_SAMPLE_FOR_STATS = 5000  # Number of samples to use for statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the MS MARCO Parquet Files\n",
    "\n",
    "Load the MS MARCO dataset from local parquet files in the `data/raw` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found train file at ../data/raw/train-00000-of-00001.parquet\n",
      "Found validation file at ../data/raw/validation-00000-of-00001.parquet\n",
      "Found test file at ../data/raw/test-00000-of-00001.parquet\n"
     ]
    }
   ],
   "source": [
    "# File paths for the parquet files\n",
    "file_paths = {\n",
    "    'train': RAW_DATA_DIR / 'train-00000-of-00001.parquet',\n",
    "    'validation': RAW_DATA_DIR / 'validation-00000-of-00001.parquet',\n",
    "    'test': RAW_DATA_DIR / 'test-00000-of-00001.parquet'\n",
    "}\n",
    "\n",
    "# Verify that the files exist\n",
    "for name, path in file_paths.items():\n",
    "    if not path.exists():\n",
    "        print(f\"Warning: {path} does not exist!\")\n",
    "    else:\n",
    "        print(f\"Found {name} file at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_msmarco_from_parquet(file_path, max_samples=None):\n",
    "    \"\"\"Load MS MARCO data from a parquet file.\"\"\"\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    \n",
    "    # Load the parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Limit the number of samples if specified\n",
    "    if max_samples is not None:\n",
    "        df = df.head(max_samples)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} rows with columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/raw/train-00000-of-00001.parquet...\n",
      "Loaded 82326 rows with columns: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers']\n",
      "Loading data from ../data/raw/validation-00000-of-00001.parquet...\n",
      "Loaded 10047 rows with columns: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers']\n",
      "Loading data from ../data/raw/test-00000-of-00001.parquet...\n",
      "Loaded 9650 rows with columns: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers']\n",
      "Using 82326 examples for processing\n"
     ]
    }
   ],
   "source": [
    "# Load data from all available files\n",
    "data_frames = {}\n",
    "for split, path in file_paths.items():\n",
    "    if path.exists():\n",
    "        try:\n",
    "            df = load_msmarco_from_parquet(path, max_samples=MAX_SAMPLES)\n",
    "            data_frames[split] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {split} data: {e}\")\n",
    "\n",
    "# Combine all splits if desired\n",
    "if len(data_frames) > 0:\n",
    "    # We can optionally combine all splits, but for now let's keep them separate\n",
    "    # all_data = pd.concat(data_frames.values(), ignore_index=True)\n",
    "    # print(f\"Combined dataset has {len(all_data)} rows\")\n",
    "    \n",
    "    # For now we'll primarily use the training data for our processing\n",
    "    main_data = data_frames.get('train', next(iter(data_frames.values())))\n",
    "    print(f\"Using {len(main_data)} examples for processing\")\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the file paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's examine the data to understand its structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample query:\n",
      "Query ID: 19699\n",
      "Query text: what is rba\n",
      "Query type: description\n",
      "\n",
      "Passages structure:\n",
      "Number of passages: 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'is_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of passages: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(passages[\u001b[33m'\u001b[39m\u001b[33mpassage_text\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Find the selected passage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m selected_indices = np.where(\u001b[43mis_selected\u001b[49m == \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Returns array of indices\u001b[39;00m\n\u001b[32m     14\u001b[39m selected_idx = selected_indices[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(selected_indices) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'is_selected' is not defined"
     ]
    }
   ],
   "source": [
    "# Display a sample row to understand the structure\n",
    "if 'main_data' in locals() and len(main_data) > 0:\n",
    "    sample_row = main_data.iloc[0]\n",
    "    print(\"Sample query:\")\n",
    "    print(f\"Query ID: {sample_row['query_id']}\")\n",
    "    print(f\"Query text: {sample_row['query']}\")\n",
    "    print(f\"Query type: {sample_row['query_type']}\")\n",
    "    print(\"\\nPassages structure:\")\n",
    "    passages = sample_row['passages']\n",
    "    print(f\"Number of passages: {len(passages['passage_text'])}\")\n",
    "    \n",
    "    # Find the selected passage\n",
    "    selected_indices = np.where(is_selected == 1)[0]  # Returns array of indices\n",
    "    selected_idx = selected_indices[0] if len(selected_indices) > 0 else None\n",
    "    \n",
    "    if selected_idx is not None:\n",
    "        print(f\"\\nSelected passage (index {selected_idx}):\")\n",
    "        selected_text = passages['passage_text'][selected_idx]\n",
    "        display_text = selected_text[:200] + \"...\" if len(selected_text) > 200 else selected_text\n",
    "        print(display_text)\n",
    "        if 'url' in passages:\n",
    "            print(f\"URL: {passages['url'][selected_idx]}\")\n",
    "    else:\n",
    "        print(\"\\nNo passage is marked as selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze query lengths\n",
    "if 'main_data' in locals() and len(main_data) > 0:\n",
    "    # Use a sample for statistics if dataset is large\n",
    "    stats_data = main_data.sample(min(USE_SAMPLE_FOR_STATS, len(main_data))) if len(main_data) > USE_SAMPLE_FOR_STATS else main_data\n",
    "    \n",
    "    query_lengths = [len(query.split()) for query in stats_data['query']]\n",
    "    avg_query_length = sum(query_lengths) / len(query_lengths) if query_lengths else 0\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(query_lengths, bins=30, alpha=0.7)\n",
    "    plt.axvline(avg_query_length, color='r', linestyle='dashed', linewidth=2, label=f'Avg: {avg_query_length:.2f} words')\n",
    "    plt.title('Distribution of Query Lengths')\n",
    "    plt.xlabel('Number of Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average query length: {avg_query_length:.2f} words\")\n",
    "    print(f\"Minimum query length: {min(query_lengths)} words\")\n",
    "    print(f\"Maximum query length: {max(query_lengths)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze passage lengths\n",
    "if 'main_data' in locals() and len(main_data) > 0:\n",
    "    # Use a sample for statistics if dataset is large\n",
    "    stats_data = main_data.sample(min(USE_SAMPLE_FOR_STATS, len(main_data))) if len(main_data) > USE_SAMPLE_FOR_STATS else main_data\n",
    "    \n",
    "    # Get selected passages\n",
    "    selected_passages = []\n",
    "    for _, row in stats_data.iterrows():\n",
    "        passages = row['passages']\n",
    "        if 1 in passages['is_selected']:\n",
    "            selected_idx = passages['is_selected'].index(1)\n",
    "            selected_passages.append(passages['passage_text'][selected_idx])\n",
    "    \n",
    "    passage_lengths = [len(passage.split()) for passage in selected_passages if passage]\n",
    "    avg_passage_length = sum(passage_lengths) / len(passage_lengths) if passage_lengths else 0\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(passage_lengths, bins=50, alpha=0.7)\n",
    "    plt.axvline(avg_passage_length, color='r', linestyle='dashed', linewidth=2, label=f'Avg: {avg_passage_length:.2f} words')\n",
    "    plt.title('Distribution of Selected Passage Lengths')\n",
    "    plt.xlabel('Number of Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average passage length: {avg_passage_length:.2f} words\")\n",
    "    print(f\"Minimum passage length: {min(passage_lengths)} words\")\n",
    "    print(f\"Maximum passage length: {max(passage_lengths)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze number of passages per query\n",
    "if 'main_data' in locals() and len(main_data) > 0:\n",
    "    # Use a sample for statistics if dataset is large\n",
    "    stats_data = main_data.sample(min(USE_SAMPLE_FOR_STATS, len(main_data))) if len(main_data) > USE_SAMPLE_FOR_STATS else main_data\n",
    "    \n",
    "    passages_per_query = [len(row['passages']['passage_text']) for _, row in stats_data.iterrows()]\n",
    "    avg_passages = sum(passages_per_query) / len(passages_per_query) if passages_per_query else 0\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(passages_per_query, bins=30, alpha=0.7)\n",
    "    plt.axvline(avg_passages, color='r', linestyle='dashed', linewidth=2, label=f'Avg: {avg_passages:.2f} passages')\n",
    "    plt.title('Distribution of Passages per Query')\n",
    "    plt.xlabel('Number of Passages')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average passages per query: {avg_passages:.2f}\")\n",
    "    print(f\"Minimum passages per query: {min(passages_per_query)}\")\n",
    "    print(f\"Maximum passages per query: {max(passages_per_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing\n",
    "\n",
    "Now, let's process the data to create our structured JSON format with queries, passages, and matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_data(df):\n",
    "    \"\"\"Extract structured data from the MS MARCO dataframe.\"\"\"\n",
    "    queries = {}\n",
    "    passages = {}\n",
    "    matches = {}\n",
    "    \n",
    "    passage_id_counter = 0\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing data\"):\n",
    "        query_id = str(row['query_id'])\n",
    "        query_text = row['query']\n",
    "        \n",
    "        # Add query to queries dictionary\n",
    "        queries[query_id] = query_text\n",
    "        \n",
    "        # Process passages\n",
    "        row_passages = row['passages']\n",
    "        passage_texts = row_passages['passage_text']\n",
    "        is_selected = row_passages['is_selected']\n",
    "        \n",
    "        # Find selected passage index\n",
    "        selected_idx = is_selected.index(1) if 1 in is_selected else None\n",
    "        \n",
    "        if selected_idx is not None:\n",
    "            # Create unique IDs for all passages in this row\n",
    "            passage_ids = [f\"p{passage_id_counter + i}\" for i in range(len(passage_texts))]\n",
    "            \n",
    "            # Add passages to passages dictionary\n",
    "            for i, (pid, text) in enumerate(zip(passage_ids, passage_texts)):\n",
    "                passages[pid] = text\n",
    "            \n",
    "            # Create match entry\n",
    "            matches[query_id] = {\n",
    "                \"suggested\": passage_ids,  # All passages\n",
    "                \"selected\": passage_ids[selected_idx]  # The selected passage\n",
    "            }\n",
    "            \n",
    "            # Increment counter for next row\n",
    "            passage_id_counter += len(passage_texts)\n",
    "    \n",
    "    return queries, passages, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "if 'main_data' in locals() and len(main_data) > 0:\n",
    "    queries, passages, matches = extract_structured_data(main_data)\n",
    "    \n",
    "    print(f\"Extracted {len(queries)} queries\")\n",
    "    print(f\"Extracted {len(passages)} passages\")\n",
    "    print(f\"Created {len(matches)} query-passage matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating JSON Structure\n",
    "\n",
    "Now, let's put everything together into our desired JSON structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataset structure\n",
    "if 'queries' in locals() and 'passages' in locals() and 'matches' in locals():\n",
    "    msmarco_data = {\n",
    "        \"queries\": queries,\n",
    "        \"passages\": passages,\n",
    "        \"matches\": matches\n",
    "    }\n",
    "    \n",
    "    # Preview the structure\n",
    "    print(\"Dataset Structure Preview:\")\n",
    "    print(f\"Number of queries: {len(msmarco_data['queries'])}\")\n",
    "    print(f\"Number of passages: {len(msmarco_data['passages'])}\")\n",
    "    print(f\"Number of matches: {len(msmarco_data['matches'])}\")\n",
    "    \n",
    "    # Show a sample match\n",
    "    if matches:\n",
    "        sample_query_id = next(iter(msmarco_data['matches']))\n",
    "        sample_match = msmarco_data['matches'][sample_query_id]\n",
    "        sample_query = msmarco_data['queries'][sample_query_id]\n",
    "        sample_selected = msmarco_data['passages'][sample_match['selected']]\n",
    "        \n",
    "        print(\"\\nSample match:\")\n",
    "        print(f\"Query ID: {sample_query_id}\")\n",
    "        print(f\"Query text: {sample_query}\")\n",
    "        print(f\"Selected passage ID: {sample_match['selected']}\")\n",
    "        display_text = str(sample_selected)[:200] + \"...\" if len(str(sample_selected)) > 200 else sample_selected\n",
    "        print(f\"Selected passage text: {display_text}\")\n",
    "        print(f\"Number of suggested passages: {len(sample_match['suggested'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading\n",
    "\n",
    "Let's save our processed data to JSON files and test loading it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to JSON files\n",
    "def save_to_json(data, file_path, pretty=True):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    indent = 4 if pretty else None\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=indent, ensure_ascii=False)\n",
    "    return file_path\n",
    "\n",
    "# Save each component separately\n",
    "if 'msmarco_data' in locals():\n",
    "    print(\"Saving data to JSON files...\")\n",
    "    queries_file = save_to_json(msmarco_data[\"queries\"], PROCESSED_DATA_DIR / \"queries.json\")\n",
    "    passages_file = save_to_json(msmarco_data[\"passages\"], PROCESSED_DATA_DIR / \"passages.json\")\n",
    "    matches_file = save_to_json(msmarco_data[\"matches\"], PROCESSED_DATA_DIR / \"matches.json\")\n",
    "    \n",
    "    print(f\"Data saved to:\\n- {queries_file}\\n- {passages_file}\\n- {matches_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the data back\n",
    "def load_from_json(file_path):\n",
    "    \"\"\"Load data from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "try:\n",
    "    print(\"Testing data loading...\")\n",
    "    loaded_queries = load_from_json(PROCESSED_DATA_DIR / \"queries.json\")\n",
    "    loaded_passages = load_from_json(PROCESSED_DATA_DIR / \"passages.json\")\n",
    "    loaded_matches = load_from_json(PROCESSED_DATA_DIR / \"matches.json\")\n",
    "    \n",
    "    print(f\"Loaded {len(loaded_queries)} queries.\")\n",
    "    print(f\"Loaded {len(loaded_passages)} passages.\")\n",
    "    print(f\"Loaded {len(loaded_matches)} matches.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading JSON files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Triplet Generation\n",
    "\n",
    "Now, let's demonstrate how to create triplets (query, positive passage, negative passage) for training our LTR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(matches, queries, passages, num_triplets=10):\n",
    "    \"\"\"Generate triplets for training with triplet loss.\"\"\"\n",
    "    triplets = []\n",
    "    \n",
    "    for query_id, match_data in matches.items():\n",
    "        positive_id = match_data[\"selected\"]\n",
    "        negative_ids = [pid for pid in match_data[\"suggested\"] if pid != positive_id]\n",
    "        \n",
    "        if negative_ids:  # Skip if no negatives\n",
    "            for negative_id in negative_ids:\n",
    "                triplet = {\n",
    "                    \"query_id\": query_id,\n",
    "                    \"query_text\": queries[query_id],\n",
    "                    \"positive_id\": positive_id,\n",
    "                    \"positive_text\": passages[positive_id],\n",
    "                    \"negative_id\": negative_id,\n",
    "                    \"negative_text\": passages[negative_id]\n",
    "                }\n",
    "                triplets.append(triplet)\n",
    "                \n",
    "                # Break if we've reached the desired number of triplets\n",
    "                if len(triplets) >= num_triplets:\n",
    "                    return triplets\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "# Generate sample triplets\n",
    "try:\n",
    "    sample_triplets = generate_triplets(loaded_matches, loaded_queries, loaded_passages, num_triplets=5)\n",
    "    \n",
    "    # Display sample triplets\n",
    "    print(f\"Generated {len(sample_triplets)} sample triplets.\")\n",
    "    for i, triplet in enumerate(sample_triplets, 1):\n",
    "        print(f\"\\nTriplet {i}:\")\n",
    "        print(f\"Query: {triplet['query_text']}\")\n",
    "        pos_display = str(triplet['positive_text'])[:100] + \"...\" if len(str(triplet['positive_text'])) > 100 else triplet['positive_text']\n",
    "        neg_display = str(triplet['negative_text'])[:100] + \"...\" if len(str(triplet['negative_text'])) > 100 else triplet['negative_text']\n",
    "        print(f\"Positive: {pos_display}\")\n",
    "        print(f\"Negative: {neg_display}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating triplets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "Now that we have prepared our data, here are the next steps for our Learning to Rank project:\n",
    "\n",
    "1. **Create the PyTorch Dataset Class**\n",
    "   - Implement a dataset class that reads our JSON files\n",
    "   - Generate triplets on-the-fly or load pre-generated triplets\n",
    "   - Apply tokenization and preprocessing\n",
    "\n",
    "2. **Implement Encoders**\n",
    "   - Start with a simple encoder for queries and documents\n",
    "   - Experiment with different architectures later\n",
    "\n",
    "3. **Implement Triplet Loss Training**\n",
    "   - Use the generated triplets to train with triplet loss\n",
    "   - Monitor training metrics\n",
    "\n",
    "4. **Evaluation**\n",
    "   - Implement ranking metrics (NDCG, MRR, etc.)\n",
    "   - Evaluate on a test set\n",
    "\n",
    "5. **Hard Negative Mining**\n",
    "   - Implement strategies for finding better negative examples\n",
    "   - Experiment with online hard negative mining\n",
    "\n",
    "The processed data we've created provides a solid foundation for these next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
