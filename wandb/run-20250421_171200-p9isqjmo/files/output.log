W&B initialized: ltr-model-20250421-171200
Loading pre-trained embedding model...
Loaded embedding model with 111712 words, dimension 100
Loaded embedding model with vocabulary size: 111712
Creating model towers...
Model towers created successfully.
Setting up dataset and dataloader...
Dataset created with 575739 triplets
Dataloader created with batch size 32
Setting up optimizer...
Optimizer created with learning rate 0.001
Total trainable parameters: 20200
Starting training...
Training progress:  40%|████████▊             | 4/10 [05:41<08:31, 85.29s/it]
Traceback (most recent call last):                                           
  Average loss: 0.1728
  Average loss: 0.1666
  Average loss: 0.1634
  Average loss: 0.1613
  File "/Users/alex/Documents/MLX/MLX_week02/src/training/train.py", line 183, in <module>
  File "/Users/alex/Documents/MLX/MLX_week02/src/training/train.py", line 118, in train
  File "/Users/alex/Documents/MLX/MLX_week02/venv/lib/python3.12/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "/Users/alex/Documents/MLX/MLX_week02/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/Users/alex/Documents/MLX/MLX_week02/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 764, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/alex/Documents/MLX/MLX_week02/venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/Users/alex/Documents/MLX/MLX_week02/src/data/triplet_dataset.py", line 82, in __getitem__
    positive_tensor = self._process_text(positive_text, self.max_length)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/alex/Documents/MLX/MLX_week02/src/data/triplet_dataset.py", line 69, in _process_text
    return torch.tensor(token_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
